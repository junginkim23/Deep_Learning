# -*- coding: utf-8 -*-

"""Conditional_DCGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OO9bvgAIxYR6A6Ql2oQN7eH7mms_P6ul

# Conditional DCGAN
Deep Convolutional GAN with Conditional input

DCGAN + CGAN

DCGAN 네트워크의 세부적인 구조는 pytorch DCGAN tutorial 공식 문서를 참조하였습니다. 

https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html
"""

import torch
import torch.nn as nn 
import torchvision 
from torchvision import transforms
from torchvision import datasets
from torch.utils.data import DataLoader
from torchvision.utils import save_image
import tqdm.notebook as tqdm

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

"""# 생성자 & 판별자"""

# Networks G & D
class conditional_dcgan_G(nn.Module):
    def __init__(self, z_dim, c_dim, img_size):
        super().__init__()
        self.img_size = img_size
        self.c_dim = c_dim
        self.G = nn.Sequential(
            nn.ConvTranspose2d(in_channels=z_dim + c_dim, out_channels=64, kernel_size=7, 
                               stride=1, padding=0, bias=False), # [64, 7, 7]
            nn.BatchNorm2d(64),
            nn.ReLU(),

            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=4, 
                               stride=2, padding=1, bias=False), # [32, 14, 14]
            nn.BatchNorm2d(32),
            nn.ReLU(),
            
            nn.ConvTranspose2d(in_channels=32, out_channels=1, kernel_size=4, 
                               stride=2, padding=1, bias=False), # [1, 28, 28]
            nn.Tanh()
        )

        for m in self.modules() :
            if isinstance(m, nn.ConvTranspose2d):
                nn.init.normal_(m.weight.data, mean=0.0, std=0.02)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.normal_(m.weight.data, 1.0, 0.02)
                nn.init.constant_(m.bias.data, 0)

    def forward(self, x, c): 
        batch_size = x.shape[0] 
        x = x.view(batch_size, -1, 1, 1) # [B, 100, 1, 1]
        c = c.view(batch_size, 1, 1, 1).expand(batch_size, self.c_dim, 1, 1) # [B, 10, 1, 1]
        out = torch.cat((x, c), dim=1) # [B, 200, 1, 1]
        out = self.G(out)
        return out 

class conditional_dcgan_D(nn.Module):
    def __init__(self, img_size):
        super().__init__()
        self.img_size = img_size
        self.D = nn.Sequential(
            nn.Conv2d(in_channels=1 +1, out_channels=32, kernel_size=4, 
                      stride=2, padding=1, bias=False), # [32, 14, 14]
            nn.BatchNorm2d(num_features=32),
            nn.LeakyReLU(negative_slope=0.2),

            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, 
                      stride=2, padding=1, bias=False), # [64, 7, 7]
            nn.BatchNorm2d(num_features=64),
            nn.LeakyReLU(negative_slope=0.2), 

            nn.Conv2d(in_channels=64, out_channels=1, kernel_size=7,
                      stride=1, padding=0, bias=False), # [1, 1, 1]
            nn.Sigmoid(),
        )

        for m in self.modules() :
            if isinstance(m, nn.Conv2d):
                nn.init.normal_(m.weight.data, mean=0.0, std=0.02)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.normal_(m.weight.data, 1.0, 0.02)
                nn.init.constant_(m.bias.data, 0)

    def forward(self, x, c): 
        batch_size = x.shape[0] # [b, 1, 28, 28]
        c = c.view(batch_size, 1, 1, 1).expand(x.size()) # [b, 1, 28, 28]
        out = torch.cat((x, c), dim=1) # [b, 2, 28, 28]
        out = self.D(out) # [batch, 1, 1, 1]
        out = out.squeeze()
        return out

"""# Loss 클래스"""

class G_Loss(nn.Module):
    def __init__(self, device):
        super(G_Loss, self).__init__()
        self.device = device 
        self.criterion = nn.BCELoss()

    def forward(self, fake):
        ones = torch.ones_like(fake).to(self.device)

        g_loss = self.criterion(fake, ones)

        return g_loss

class D_Loss(nn.Module):
    def __init__(self, device):
        super(D_Loss, self).__init__()
        self.device = device
        self.criterion = nn.BCELoss()

    def forward(self, D_real, D_fake):
        ones = torch.ones_like(D_real).to(self.device)
        zeros = torch.zeros_like(D_fake).to(self.device)

        d_real_loss = self.criterion(D_real, ones)
        d_fake_loss = self.criterion(D_fake, zeros)

        d_loss = d_real_loss + d_fake_loss

        return d_loss, d_real_loss, d_fake_loss

"""# Hyper parameters 및 save 폴더 준비"""

# reset folder 
!rm -r G_ckpt D_ckpt fake_images

# make save folders 
!mkdir G_ckpt D_ckpt fake_images
G_ckpt_folder = 'G_ckpt' 
D_ckpt_folder = 'D_ckpt' 
fake_img_folder = 'fake_images'

# Hyper-parameters 
num_epochs = 20
batch_size = 100
img_size = 28
save_step_interval = 300

# 모델 Hyper-parameters
z_dim = 100 
c_dim = 10 
num_show_img = 50
lr_G = 0.0002
lr_D = 0.0002
beta1 = 0.5 
beta2 = 0.999

"""# 데이터"""

# dataset & loader 
transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize(mean=0.5, std=0.5)])

mnist_dataset = datasets.MNIST(root='./data', train=True, 
                               transform=transform, download=True)

mnist_loader = DataLoader(dataset=mnist_dataset, 
                          batch_size=batch_size, 
                          shuffle=True)

def to_img(x): 
    return torch.clamp((x+1)/2, 0, 1)

"""# 학습 준비"""

# 모델 올리기 
G = conditional_dcgan_G(z_dim, c_dim, img_size).to(device)
D = conditional_dcgan_D(img_size).to(device)

# Loss 
G_loss = G_Loss(device)
D_loss = D_Loss(device)

# optimizer 
G_optim = torch.optim.Adam(G.parameters(), lr=lr_G, betas=(beta1, beta2))
D_optim = torch.optim.Adam(D.parameters(), lr=lr_D, betas=(beta1, beta2))

# 이미지 생성에 사용할 고정 label과 random number
eval_c = torch.tensor([0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9], 
                      dtype=torch.float32).to(device)
eval_z = torch.randn(eval_c.shape[0], z_dim).to(device)

"""# 학습"""

# Train
for epoch in tqdm.tqdm(range(num_epochs)): 
    for i, (images, labels) in enumerate(mnist_loader):
        G.train()
        D.train()
        images = images.to(device)
        labels = labels.to(device)

        ### update D ### 
        z = torch.randn(batch_size, z_dim).to(device)
        fake_images = G(z, labels)

        D_real = D(images, labels)
        D_fake = D(fake_images.detach(), labels)

        d_loss, d_real_loss, d_fake_loss = D_loss(D_real, D_fake)

        D_optim.zero_grad()
        d_loss.backward()
        D_optim.step()
        
        ### update G ### 
        z = torch.randn(batch_size, z_dim).to(device)
        fake_images = G(z, labels)

        G_fake = D(fake_images, labels)

        g_loss = G_loss(G_fake)

        G_optim.zero_grad()
        g_loss.backward()
        G_optim.step()

        ### save middle ckpt and fake img ### 
        if i % save_step_interval == 0 : 
            with torch.no_grad():
                save_name = f'{str(epoch+1).zfill(3)}_{str(i).zfill(3)}'
                G.eval()
                D.eval()
                torch.save(G.state_dict(), f'{G_ckpt_folder}/G_model_{save_name}.ckpt')
                torch.save(D.state_dict(), f'{D_ckpt_folder}/D_model_{save_name}.ckpt')
                
                fake_images = G(eval_z, eval_c)
                save_image(to_img(fake_images), 
                           f'{fake_img_folder}/gen_imgs_{save_name}.jpg')

    print(f'EPOCH {epoch+1} LOSS value G : {g_loss:.4f} / D(r, f) : {d_loss:.4f} ({d_real_loss:.4f} , {d_fake_loss:.4f})')

"""# 결과 gif 만들기"""

import os
from PIL import Image

fp_in = fake_img_folder
fp_out = 'conditional_dcgan_results.gif'

# img : list의 가장 첫 element 
# *imgs : list의 가장 첫 element를 제외한 나머지 element를 list로 담아오기 
img, *imgs = [Image.open(os.path.join(fp_in, f)) for f in sorted(os.listdir(fp_in))] 
img.save(fp=fp_out, format='GIF', append_images=imgs,
         save_all=True, duration=100, loop=0)

