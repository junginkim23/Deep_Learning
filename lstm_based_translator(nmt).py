# -*- coding: utf-8 -*-
"""LSTM-based translator(NMT)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1weMB3zV7o7ipJCJV0ZwOLkwLPKlbsbaZ
"""

# Drive 마운트 
# 학습에 사용할 데이터를 본인의 Drive에 업로드하고 해당 위치를 적어주기 
!unzip -qq drive/MyDrive/AI\ School/12주차/seq2seq_NMTdata.zip -d . #-qq: 밑에 실행되는 것들을 없애주는 코드
!rm -r __MACOSXA

from google.colab import drive
drive.mount('/content/drive')

# strip() 메소드: 문장의 양쪽에서 주어진 인자 제거 
# a="hi my name is kimjungin"
# a.split(' ').\ strip()

test = "에러 1222: 레퍼런스 오류\n 에러 1033: 아규먼트 오류"
regex = re.compile("에러 1033") #정규식 객체(re.RegexObject 클래스 객체) 리턴 
mo = regex.search(test) #search(): 검색 대상이 있으면 결과를 갖는 MatchObject 객체를 리턴한다. 맞는 문자열이 없으면 None을 리턴한다. 
print(type(mo))
if mo != None:
  print(mo.group())

"""아래 코드는 pytorch seq2seq 공식 튜토리얼 문서를 참조했습니다. 

https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html
"""

from io import open
import unicodedata
import re 
#정규표현식: 특정한 규칙을 가진 문자열의 패턴을 표현하는 데 사용하는 표현식으로 텍스트에서 특정 문자열을 검색하거나 치환할 때 흔히 사용된다. 
import random

import torch
import torch.nn as nn
from torch import optim
import torch.nn.functional as F

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

"""# 데이터 불러오기"""

SOS_token = 0 # Start of Sentence 
EOS_token = 1 # End of Sentence

class Lang:
    def __init__(self, name):
        self.name = name
        self.word2index = {} #예를 들어, I라는 단어가 들어 왔을 때, I의 index가 몇 인지를 알 수 있는 객체 
        self.word2count = {} #이러한 I가 몇 개 있는지 총 개수를 알고 있는 객체 
        self.index2word = {0: "SOS", 1: "EOS"} #SOS(문장의 시작을 알려준다.) EOS(문장의 끝을 알려준다.)
        self.n_words = 2  # SOS & EOS 카운트 

    def addSentence(self, sentence): 
        for word in sentence.split(' '):
            self.addWord(word)

    def addWord(self, word):
        if word not in self.word2index:
            self.word2index[word] = self.n_words
            self.word2count[word] = 1
            self.index2word[self.n_words] = word
            self.n_words += 1
        else:
            self.word2count[word] += 1

def unicodeToAscii(s):
    return ''.join(
        c for c in unicodedata.normalize('NFD', s)
        if unicodedata.category(c) != 'Mn'
    )

# 소문자, trim, unicode -> Ascii and 문자가 아닌 글자 제거, trim: 필요없는 문자 제거 
def normalizeString(s):
    s = unicodeToAscii(s.lower().strip())
    s = re.sub(r"([.!?])", r" \1", s) #re.sub
    s = re.sub(r"[^a-zA-Z.!?]+", r" ", s)
    return s

def readLangs(lang1, lang2, reverse=False):
    print("Reading lines...")

    # 파일 읽고 줄 단위로 나누기 
    lines = open('seq2seq_NMTdata/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\
        read().strip().split('\n')
    #open().\ ?? 

    # 각 줄을 pairs 단위로 나누고 normalize 함수 진행 
    pairs = [[normalizeString(s) for s in l.split('\t')] for l in lines]

    # Lang 객체 생성, 필요시 reverse 진행
    if reverse:
        pairs = [list(reversed(p)) for p in pairs]
        input_lang = Lang(lang2)
        output_lang = Lang(lang1)
    else:
        input_lang = Lang(lang1)
        output_lang = Lang(lang2)

    return input_lang, output_lang, pairs

MAX_LENGTH = 10

eng_prefixes = (
    "i am ", "i m ",
    "he is", "he s ",
    "she is", "she s ",
    "you are", "you re ",
    "we are", "we re ",
    "they are", "they re "
)


def filterPair(p): #filter하는 메소드 
    return len(p[0].split(' ')) < MAX_LENGTH and \
        len(p[1].split(' ')) < MAX_LENGTH and \
        p[1].startswith(eng_prefixes) #string에 있는 파이썬 문법: startswith() -> p[1]안에 문장이 eng_prefixes로 시작하는 것들은 true 아니면 false 


def filterPairs(pairs): #내가 원하는 문장들만 가지고 온다. 
    return [pair for pair in pairs if filterPair(pair)]

# 1. 파일을 읽어서 줄로 나누고 pair로 나누기 
# 2. normalize 시키고 pair를 filter에 통과시키기(Max legnth와 prefixes에 맞는 애들로)
# 3. Pairs 안에 있는 문장으로 단어 리스트 생성 
def prepareData(lang1, lang2, reverse=False):
    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)
    print("Read %s sentence pairs" % len(pairs))
    pairs = filterPairs(pairs)
    print("Trimmed to %s sentence pairs" % len(pairs))
    print("Counting words...")
    for pair in pairs:
        input_lang.addSentence(pair[0])
        output_lang.addSentence(pair[1])
    print("Counted words:")
    print(input_lang.name, input_lang.n_words)
    print(output_lang.name, output_lang.n_words)
    return input_lang, output_lang, pairs


input_lang, output_lang, pairs = prepareData('eng', 'fra', True)
print(random.choice(pairs))

"""# Encoder

입력으로 들어오는 언어의 내용을 잘 간추려 하나의 vector로 만듦
"""

class EncoderLSTM(nn.Module):
    def __init__(self, input_size, hidden_size):
        super(EncoderLSTM, self).__init__()
        self.hidden_size = hidden_size

        self.embedding = nn.Embedding(input_size, hidden_size)
        self.lstm = nn.LSTM(hidden_size, hidden_size)
#tensor(output) -> [SL, batch, embedding] SL: Sentence Length

    def forward(self, input, hidden, cell):#hidden, cell 은 t-1의 시점에서 나온 값들이다. 
        embedded1 = self.embedding(input)
        print(embedded1)
        embedded = self.embedding(input).view(1, 1, -1) #view(1,1,-1) 
        print(embedded)
        output = embedded
        output, (hidden, cell) = self.lstm(output, (hidden, cell))
        return output, hidden, cell

    def initHidden(self):
        return torch.zeros(1, 1, self.hidden_size, device=device)

"""# Decoder

Encoder에서 만들어 낸 vector를 이용해 출력 단어를 뱉어줌
"""

class DecoderLSTM(nn.Module):
    def __init__(self, hidden_size, output_size):
        super(DecoderLSTM, self).__init__()
        self.hidden_size = hidden_size

        self.embedding = nn.Embedding(output_size, hidden_size)
        self.lstm = nn.LSTM(hidden_size, hidden_size)
        self.out = nn.Linear(hidden_size, output_size)
        # output_size -> vocab size
        self.softmax = nn.LogSoftmax(dim=1) #LogSoftmax -> 연산이 많아서 안정적으로 하기 위해 softmax를 시행하는데, 이때 LogSoftmax를 씌운다. 

    def forward(self, input, hidden, cell):
        output = self.embedding(input).view(1, 1, -1)
        output = F.relu(output) #학습의 불안정이 생길 수 있다.  
        output, (hidden, cell) = self.lstm(output, (hidden, cell))
        output = self.softmax(self.out(output[0])) 
        return output, hidden, cell

    def initHidden(self):
        return torch.zeros(1, 1, self.hidden_size, device=device)

"""# 한 pair의 Train 과정

전체 학습 데이터가 아니라 language1과 language2 데이터 한 쌍의 학습 과정

lang1을 encoding 하고 lang2로 decoding해서 loss를 구하고 각각의 optimizer로 update
"""

teacher_forcing_ratio = 0.5

def train(input_tensor, target_tensor, encoder, decoder, \
          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):
    encoder_hidden = encoder.initHidden()
    encoder_cell = encoder.initHidden()

    encoder_optimizer.zero_grad()
    decoder_optimizer.zero_grad()

    input_length = input_tensor.size(0)
    target_length = target_tensor.size(0)
    
    for ei in range(input_length):
        encoder_output, encoder_hidden, encoder_cell = encoder(input_tensor[ei], 
                                                               encoder_hidden,
                                                               encoder_cell)
    
    decoder_input = torch.tensor([[SOS_token]], device=device)
    decoder_hidden = encoder_hidden
    decoder_cell = encoder_cell

    loss = 0
    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False
    if use_teacher_forcing:
        # Teacher forcing: 네트워크가 뱉어낸 출력물과는 상관없이 실제 정답을 decoder의 다음 입력으로 사용
        for di in range(target_length):
            decoder_output, decoder_hidden, decoder_cell = decoder(decoder_input, 
                                                                   decoder_hidden,
                                                                   decoder_cell)
            loss += criterion(decoder_output, target_tensor[di])
            decoder_input = target_tensor[di]  # Teacher forcing

    else:
        # Without teacher forcing: 네트워크가 뱉어낸 출력물 자체를 decoder의 다음 입력으로 사용
        for di in range(target_length):
            decoder_output, decoder_hidden, decoder_cell = decoder(decoder_input, 
                                                                   decoder_hidden,
                                                                   decoder_cell)
            topv, topi = decoder_output.topk(1)
            decoder_input = topi.squeeze().detach()  # detach from history as input

            loss += criterion(decoder_output, target_tensor[di])
            if decoder_input.item() == EOS_token:
                break

    loss.backward()
    encoder_optimizer.step()
    decoder_optimizer.step()
    return loss.item() / target_length

"""# Helper 함수

진행도와 남은 학습 상황을 보여주는 도우미 함수
"""

import time
import math

def asMinutes(s):
    m = math.floor(s / 60)
    s -= m * 60
    return '%dm %ds' % (m, s)

def timeSince(since, percent):
    now = time.time()
    s = now - since
    es = s / (percent)
    rs = es - s
    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))

"""# PLT show 함수"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
plt.switch_backend('agg')
import matplotlib.ticker as ticker
import numpy as np
# %matplotlib inline

def showPlot(points):
    plt.figure()
    fig, ax = plt.subplots()

    loc = ticker.MultipleLocator(base=0.2)
    ax.yaxis.set_major_locator(loc)
    plt.plot(points)

"""# 전체 Train 과정

전체 학습 과정을 담당하는 코드 

다음의 과정이 담겨있다

1. 타이머 시작 세팅 
2. Encoder와 Decoder optimizer 선언 
3. Loss 선언 
4. 전체 데이터를 학습에 사용할 수 있는 형태로 불러오기 
5. 각 데이터 pair를 train 시키기 
6. 전체 loss update 
7. 시각화
"""

def indexesFromSentence(lang, sentence):
    return [lang.word2index[word] for word in sentence.split(' ')]

def tensorFromSentence(lang, sentence):
    indexes = indexesFromSentence(lang, sentence)
    indexes.append(EOS_token)
    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)

def tensorsFromPair(pair):
    input_tensor = tensorFromSentence(input_lang, pair[0])
    target_tensor = tensorFromSentence(output_lang, pair[1])
    return (input_tensor, target_tensor)

def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):
    start = time.time()
    plot_losses = []
    print_loss_total = 0  # Reset every print_every
    plot_loss_total = 0   # Reset every plot_every

    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)
    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)
    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]
    criterion = nn.NLLLoss()

    for iter in range(1, n_iters + 1):
        training_pair = training_pairs[iter - 1]
        input_tensor = training_pair[0]
        target_tensor = training_pair[1]

        loss = train(input_tensor, target_tensor, encoder, decoder, 
                     encoder_optimizer, decoder_optimizer, criterion)
        print_loss_total += loss
        plot_loss_total += loss

        if iter % print_every == 0:
            print_loss_avg = print_loss_total / print_every
            print_loss_total = 0
            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),
                                         iter, iter / n_iters * 100, print_loss_avg))

        if iter % plot_every == 0:
            plot_loss_avg = plot_loss_total / plot_every
            plot_losses.append(plot_loss_avg)
            plot_loss_total = 0

    showPlot(plot_losses)

"""# 실제 학습 시작 지점"""

hidden_size = 256
n_iter = 75000
print_every = 5000

encoder = EncoderLSTM(input_lang.n_words, hidden_size).to(device)
decoder = DecoderLSTM(hidden_size, output_lang.n_words).to(device)

trainIters(encoder, decoder, n_iter, print_every=print_every)

"""# Evaluate

Decoding과정에서 만들어진 t 시점의 출력물이 t+1 시점의 입력으로 들어가도록 설계
"""

def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):
    with torch.no_grad():
        input_tensor = tensorFromSentence(input_lang, sentence)
        input_length = input_tensor.size()[0]
        encoder_hidden = encoder.initHidden()
        encoder_cell = encoder.initHidden()

        for ei in range(input_length):
            encoder_output, encoder_hidden, encoder_cell = encoder(input_tensor[ei],
                                                                   encoder_hidden,
                                                                   encoder_cell)
        
        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS

        decoder_hidden = encoder_hidden
        decoder_cell = encoder_cell

        decoded_words = []

        for di in range(max_length):
            decoder_output, decoder_hidden, decoder_cell = decoder(decoder_input, 
                                                                   decoder_hidden,
                                                                   decoder_cell)
            topv, topi = decoder_output.data.topk(1)
            if topi.item() == EOS_token:
                decoded_words.append('<EOS>')
                break
            else:
                decoded_words.append(output_lang.index2word[topi.item()])

            decoder_input = topi.squeeze().detach()

        return decoded_words

def evaluateRandomly(encoder, decoder, n=10):
    for i in range(n):
        pair = random.choice(pairs)
        print('>', pair[0])
        print('=', pair[1])
        output_words = evaluate(encoder, decoder, pair[0])
        output_sentence = ' '.join(output_words)
        print('<', output_sentence)
        print('')

evaluateRandomly(encoder, decoder)

sentence = 'il est sur le bureau .'
output_words = evaluate(encoder, decoder, sentence)
output_sentence = ' '.join(output_words)
print('>', sentence)
print('<', output_sentence)

