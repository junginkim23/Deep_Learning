# -*- coding: utf-8 -*-
"""confirming how to find a score of similarity pair using pretrained word2vec

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LU4blkBa1H6kuIj6Px-rWJrZTPL_7hGz
"""

from gensim.models.keyedvectors import KeyedVectors
import time

# 본인의 Drive를 연결하고 파일의 위치를 정확히 입력해야 함
# 띄어쓰기의 경우는 띄어쓰기 앞에 역슬래쉬(\) 기호를 넣고 띄어줘야 함 
# cp : copy 명령어 
# cp A B : A를 복사해서 B의 위치에 붙여 넣어라 

!cp drive/MyDrive/AI\ School/8주차/GoogleNews-vectors-negative300.bin.gz . #.의 의미는 현재 내 위치를 의미한다. 
!gunzip -k GoogleNews-vectors-negative300.bin.gz #-k(keep) 원래 알집 파일을 지우지 마라는 의미.

from google.colab import drive
drive.mount('/content/drive')

s = time.time()
model = KeyedVectors.load_word2vec_format("./GoogleNews-vectors-negative300.bin", 
                                          binary=True, 
                                         limit=60000)
print(time.time() - s)

#similarity between two words 
print("similarity between apple and fruit: {}".format(model.similarity("apple", "fruit")))
print("similarity between apple and car: {}".format(model.similarity("apple", "car")))
print("similarity between school and university: {}".format(model.similarity("school", "university")))
print("similarity between AI and artificial_intelligence: {}".format(model.similarity("AI", "artificial_intelligence")))
print("similarity between man and king: {}".format(model.similarity("man", "king")))
print("similarity between president and king: {}".format(model.similarity("president", "king")))
print("similarity between Apple and Samsung: {}".format(model.similarity("Apple", "Samsung")))
print("similarity between China and Hong_Kong: {}".format(model.similarity("China", "Hong_Kong")))
print("similarity between us and them: {}".format(model.similarity("us", "them")))
print("similarity between South_Korea and North_Korea: {}".format(model.similarity("South_Korea", "North_Korea")))
# print(model.most_similar("South_Korea", topn=10))

# Check score of similarity pair
print(model.most_similar(positive=['king', 'women'], negative=['man'], topn=10))
print(model.most_similar(positive=['North_Korea', 'Seoul'], negative=['South_Korea'], topn=10))
print(model.most_similar(positive=['Korea', 'Beijing'], negative=['china'], topn=10))
print(model.most_similar(positive=['people', 'women'], negative=['man'], topn=10))
print(model.most_similar(positive=['country', 'man'], negative=['country'], topn=10))
print(model.most_similar(positive=['Japan', 'South_Korea'], negative=['Japanese'], topn=10))
print(model.most_similar(positive=['USA', 'Seoul'], negative=['South_Korea'], topn=10))
print(model.most_similar(positive=['France', 'Washington_DC'], negative=['USA'], topn=10))
print(model.most_similar(positive=['Europe', 'Paris'], negative=['France'], topn=10))
print(model.most_similar(positive=['China', 'Seoul'], negative=['South_Korea'], topn=10))

!cp drive/MyDrive/AI\ School/8주차/news1.txt .

from gensim.models import Word2Vec
from gensim.models.word2vec import LineSentence

sentences = LineSentence("news1.txt")
model = Word2Vec(sentences, size=100, window=5, min_count=1, workers=4)
model.save("word2vec.model")

model = Word2Vec.load("word2vec.model")
print(model.wv.most_similar("car", topn=200))
print(len(model.wv.vocab))